program: cs336_basics/training_together.py
method: bayes
command:
  - ${env}
  - uv
  - run
  - python
  - ${program}
  - --tokenizer_dir=tokenizer/tiny/
  - --train_path=tokenized/tokenized-tiny-TinyStoriesV2-GPT4-train.bin
  - --valid_path=tokenized/tokenized-tiny-TinyStoriesV2-GPT4-valid.bin
  - --eval_every=500
  - --use_wandb
  - --device=cuda:0
  - ${args}
metric:
  name: eval/perplexity
  goal: minimize
parameters:
  batch_size:
    values: [4, 8, 16, 32]
  d_model:
    values: [256, 512, 1024]
  num_layers:
    values: [2, 4, 6]
  num_heads:
    values: [8, 16]
  d_ff:
    values: [1024, 2048, 4096]
  alpha_max:
    min: 1e-4
    max: 1e-2
    distribution: log_uniform_values
  alpha_min:
    min: 1e-6
    max: 1e-4
    distribution: log_uniform_values